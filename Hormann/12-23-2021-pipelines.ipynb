{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-23T22:00:18.399757Z","iopub.execute_input":"2021-12-23T22:00:18.400099Z","iopub.status.idle":"2021-12-23T22:00:18.415608Z","shell.execute_reply.started":"2021-12-23T22:00:18.400061Z","shell.execute_reply":"2021-12-23T22:00:18.414511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:43:53.790944Z","iopub.execute_input":"2021-12-29T21:43:53.791965Z","iopub.status.idle":"2021-12-29T21:43:53.820943Z","shell.execute_reply.started":"2021-12-29T21:43:53.791844Z","shell.execute_reply":"2021-12-29T21:43:53.820203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pokemon/pokemon.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:43:53.822326Z","iopub.execute_input":"2021-12-29T21:43:53.822815Z","iopub.status.idle":"2021-12-29T21:43:53.864918Z","shell.execute_reply.started":"2021-12-29T21:43:53.822783Z","shell.execute_reply":"2021-12-29T21:43:53.863916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:43:59.920282Z","iopub.execute_input":"2021-12-29T21:43:59.920599Z","iopub.status.idle":"2021-12-29T21:43:59.965822Z","shell.execute_reply.started":"2021-12-29T21:43:59.92056Z","shell.execute_reply":"2021-12-29T21:43:59.964755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_missing_val = df.columns[df.isnull().any()].tolist()\nprint(cols_missing_val)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:47:54.878804Z","iopub.execute_input":"2021-12-29T21:47:54.879118Z","iopub.status.idle":"2021-12-29T21:47:54.887741Z","shell.execute_reply.started":"2021-12-29T21:47:54.879089Z","shell.execute_reply":"2021-12-29T21:47:54.887079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:47:55.159664Z","iopub.execute_input":"2021-12-29T21:47:55.160175Z","iopub.status.idle":"2021-12-29T21:47:55.163969Z","shell.execute_reply.started":"2021-12-29T21:47:55.160107Z","shell.execute_reply":"2021-12-29T21:47:55.162979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(column, df):\n    fig, ax = plt.subplots(figsize=(10, 5))\n    print(column)\n    df[column].hist(ax=ax)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:47:55.843454Z","iopub.execute_input":"2021-12-29T21:47:55.844546Z","iopub.status.idle":"2021-12-29T21:47:55.851685Z","shell.execute_reply.started":"2021-12-29T21:47:55.844482Z","shell.execute_reply":"2021-12-29T21:47:55.85027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cols_missing_val:\n    plot_hist(col, df)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:47:56.363799Z","iopub.execute_input":"2021-12-29T21:47:56.364276Z","iopub.status.idle":"2021-12-29T21:47:57.418076Z","shell.execute_reply.started":"2021-12-29T21:47:56.364239Z","shell.execute_reply":"2021-12-29T21:47:57.417203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom abc import ABC, abstractmethod\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:47:57.422608Z","iopub.execute_input":"2021-12-29T21:47:57.422891Z","iopub.status.idle":"2021-12-29T21:47:58.833101Z","shell.execute_reply.started":"2021-12-29T21:47:57.422857Z","shell.execute_reply":"2021-12-29T21:47:58.832197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.is_legendary.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:48:01.698075Z","iopub.execute_input":"2021-12-29T21:48:01.698447Z","iopub.status.idle":"2021-12-29T21:48:01.711949Z","shell.execute_reply.started":"2021-12-29T21:48:01.698408Z","shell.execute_reply":"2021-12-29T21:48:01.711187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_dataset(dataset, split_instance):\n    \"\"\"\n    Split the dataset using a split instance which should has a\n    split method. Returns a dict with the split dataset.\n    \"\"\"\n    return split_instance.split(dataset)\n\nclass Split(ABC):\n    \"\"\"Split dataset abstract class.\"\"\"\n\n    @abstractmethod\n    def split(self, dataset):\n        \"\"\"split method.\n\n        Should return the data splits.\n        \"\"\"\n        pass\n\nclass SplitDefault(Split):\n    \"\"\"Split dataset into train, validation, full_train and test.\"\"\"\n\n    def __init__(self, split_col='is_legendary'):\n        self._split_col = split_col\n\n    def split(self, df):\n        X = df.drop('is_legendary', axis=1)\n        y = df['is_legendary']\n        X_full_train, X_test, y_full_train, y_test = train_test_split(\n            X, y, random_state=77, stratify=y, train_size=.8\n        )\n\n        X_train, X_valid, y_train, y_valid = train_test_split(\n            X_full_train, y_full_train, random_state=77, stratify=y_full_train, train_size=.8\n        )\n\n        return {\n            'train': (X_train, y_train),\n            'valid': (X_valid, y_valid),\n            'full_train': (X_full_train, y_full_train),\n            'test': (X_test, y_test),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:48:55.663254Z","iopub.execute_input":"2021-12-29T21:48:55.663594Z","iopub.status.idle":"2021-12-29T21:48:55.675157Z","shell.execute_reply.started":"2021-12-29T21:48:55.663562Z","shell.execute_reply":"2021-12-29T21:48:55.673869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ColumnSelectorTransformer(BaseEstimator, TransformerMixin):\n\n    def __init__(self, cols_to_eliminate):\n        self._cols_to_eliminate = cols_to_eliminate # lista de columnas no deseadas\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        \"\"\"Transform method. X is a pandas dataframe.\"\"\"\n        return X.drop(self._cols_to_eliminate, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:49:02.855871Z","iopub.execute_input":"2021-12-29T21:49:02.856502Z","iopub.status.idle":"2021-12-29T21:49:02.863175Z","shell.execute_reply.started":"2021-12-29T21:49:02.856454Z","shell.execute_reply":"2021-12-29T21:49:02.862013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def processing_1():\n    return Pipeline([\n        ('column_selector', ColumnSelectorTransformer(cols_to_eliminate=['abilities']))\n    ])\n\ndef processing_2():\n    return Pipeline([\n        ('column_selector', ColumnSelectorTransformer(cols_to_eliminate=['abilities'])),\n        ('simple_imputer', SimpleImputer(strategy='most_frequent'))\n    ])\n\ndef processing_3():\n    return Pipeline([\n        ('column_selector', ColumnSelectorTransformer(cols_to_eliminate=['abilities'])),\n        ('simple_imputer', SimpleImputer(strategy='constant', fill_value='hormann'))\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T21:54:52.666989Z","iopub.execute_input":"2021-12-29T21:54:52.667469Z","iopub.status.idle":"2021-12-29T21:54:52.674412Z","shell.execute_reply.started":"2021-12-29T21:54:52.667435Z","shell.execute_reply":"2021-12-29T21:54:52.673382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_pipeline(df, func_pipe_to_run, convert_to_pandas=False):\n    pipeline = func_pipe_to_run()\n    split_instance = SplitDefault()\n    # split the data\n    split_data = split_dataset(df.copy(), split_instance)\n\n    # fit and transform only in train\n    pipeline.fit(split_data['train'][0], split_data['train'][1])\n    X_train_new = pipeline.transform(split_data['train'][0])\n    # transform in validation\n    X_valid_new = pipeline.transform(split_data['valid'][0])\n\n    # fit and transform only in full train\n    pipeline.fit(split_data['full_train'][0], split_data['full_train'][1])\n    X_full_train_new = pipeline.transform(split_data['full_train'][0])\n    # transform in test\n    X_test_new = pipeline.transform(split_data['test'][0])\n    \n    if convert_to_pandas:\n        columns = list(split_data['train'][0].columns)\n        columns = columns[1:]\n        X_train_new = pd.DataFrame(X_train_new, columns=columns)\n        X_valid_new = pd.DataFrame(X_train_new, columns=columns)\n        X_full_train_new = pd.DataFrame(X_train_new, columns=columns)\n        X_test_new = pd.DataFrame(X_train_new, columns=columns)\n\n    return {\n        'train': (X_train_new, split_data['train'][1]),\n        'valid': (X_valid_new, split_data['valid'][1]),\n        'full_train': (X_full_train_new, split_data['full_train'][1]),\n        'test': (X_test_new, split_data['test'][0])\n    }","metadata":{"execution":{"iopub.status.busy":"2021-12-29T22:36:14.883573Z","iopub.execute_input":"2021-12-29T22:36:14.883911Z","iopub.status.idle":"2021-12-29T22:36:14.896391Z","shell.execute_reply.started":"2021-12-29T22:36:14.883877Z","shell.execute_reply":"2021-12-29T22:36:14.895104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions","metadata":{}},{"cell_type":"code","source":"data_after_pipeline = run_pipeline(df, processing_1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T22:31:11.778759Z","iopub.execute_input":"2021-12-29T22:31:11.779429Z","iopub.status.idle":"2021-12-29T22:31:11.795588Z","shell.execute_reply.started":"2021-12-29T22:31:11.779388Z","shell.execute_reply":"2021-12-29T22:31:11.794494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_after_pipeline['train'][0].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T22:31:18.48522Z","iopub.execute_input":"2021-12-29T22:31:18.485631Z","iopub.status.idle":"2021-12-29T22:31:18.516931Z","shell.execute_reply.started":"2021-12-29T22:31:18.485601Z","shell.execute_reply":"2021-12-29T22:31:18.515936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_after_pipeline = run_pipeline(df, processing_2, convert_to_pandas=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T22:36:19.958156Z","iopub.execute_input":"2021-12-29T22:36:19.958735Z","iopub.status.idle":"2021-12-29T22:36:20.07214Z","shell.execute_reply.started":"2021-12-29T22:36:19.958602Z","shell.execute_reply":"2021-12-29T22:36:20.070705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_after_pipeline['train'][0].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T22:36:23.080499Z","iopub.execute_input":"2021-12-29T22:36:23.081052Z","iopub.status.idle":"2021-12-29T22:36:23.108963Z","shell.execute_reply.started":"2021-12-29T22:36:23.081015Z","shell.execute_reply":"2021-12-29T22:36:23.107655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}